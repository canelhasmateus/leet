{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Estudo do Atraso de Voos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Obtenção e primeira exploração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import database\n",
    "from voos import voos_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados = pd.DataFrame()\n",
    "\n",
    "urls = [ ]\n",
    "for year in range( 2020, 2020 + 1 ):\n",
    "    for month in range( 1, 12 + 1 ):\n",
    "        month = str( month ) if month >= 10 else \"0\" + str( month )\n",
    "        url = f\"https://www.gov.br/anac/pt-br/assuntos/regulados/empresas-aereas/envio-de-informacoes/microdados/basica{year}-{month}.zip\"\n",
    "        urls.append( url )\n",
    "\n",
    "for url in tqdm( urls ):\n",
    "    parcial = pd.read_csv( url, encoding = \"latin1\", sep = \";\" ).sample( frac = 0.05, random_state = 2 )\n",
    "    microdados = pd.concat( [ microdados, parcial ], axis = 0 )\n",
    "\n",
    "url_est = 'https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/dados-estatisticos/arquivos/resumo_anual_2010.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Da definição:\n",
    "\n",
    "Etapa Básica (flight stage): As etapas básicas são aquelas realizadas pela aeronave desde a sua decolagem até o próximo pouso, independentemente de onde tenha ocorrido o embarque ou o desembarque do objeto de transporte.\n",
    "\n",
    "Os dados estatísticos das etapas básicas representam o status da aeronave em cada etapa do voo, apresentando a movimentação de cargas e passageiros entre os aeródromos de origem e destino da aeronave. É a operação de uma aeronave entre um a decolagem e o próximo pouso, a ligação entre dois aeródromos.\n",
    "\n",
    "Etapa Combinada (On flight origin and destination - OFOD): As etapas combinadas identificam os pares de origem, onde ocorreu o embarque do objeto de transporte, e destino, onde ocorreu o desembarque do objeto de transporte, independentemente da existência de aeródromos intermediários, atendidos por determinado voo.\n",
    "\n",
    "É a etapa de voo vista com foco no objeto de transporte (pessoas e/ou cargas), com base no embarque e no desembarque nos aeródromos relacionados. Os dados estatísticos da etapa combinada informam a origem e destino dos passageiros e cargas transportadas no voo, independentemente das escalas realizadas.\n",
    "\n",
    "\n",
    "Aqui olharemos primeiramente para a etapa basica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.duplicated( [ \"id_basica\" ] ).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "De Fato, id basica é uma pk ( identificador unico ) nessa tabela, e não temos nenhum registro duplicado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(microdados.isna().sum( axis = 0 ) / microdados.shape[ 0 ]).sort_values( ascending = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "nr escala destino é 100% nulo. Doideira ( Isso provavelmente é algum tipo de informação que foi dropada ao longo do tempo. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique = microdados.nm_empresa.value_counts()\n",
    "cumulative = unique.cumsum()\n",
    "cumulative = cumulative / unique.sum()\n",
    "cumulative.sort_values( ascending = True ).iloc[ :15 ].plot( kind = \"bar\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Nenhuma surpresa aqui: a gigantesca maioria das etapas é realizada por poucas empresas\n",
    "Aprox. 80% das etapas é feita por apenas 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.groupby( [ \"nr_mes_referencia\", \"nm_mes_referencia\" ] ).count()[ \"id_basica\" ].sort_index( ascending = True ).plot( kind = \"bar\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados[ \"nr_dia_semana_referencia\" ] = pd.to_datetime( microdados[ \"dt_referencia\" ], infer_datetime_format = True ).dt.dayofweek\n",
    "\n",
    "microdados.groupby( [ \"nr_dia_semana_referencia\", \"nm_dia_semana_referencia\" ] ).count()[ \"id_basica\" ].sort_index( ascending = True ).plot( kind = \"bar\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Aqui temos uma surpresa: Fim de semanas são dias com menos voos? Interessante. [quinta, sexta, segunda, quarta, terca ] são dias de ocupação bem proxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "microdados.query(\"nm_pais != 'BRASIL'\").groupby(\"nm_pais\").nunique()[\"nm_empresa\"].nlargest(10).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Essas são as nacionalidades das empresas não brasileiras dentro do dataset. USA domina, seguido de argentina, chile, venezuela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.groupby( [ \"nm_municipio_destino\", \"nm_municipio_origem\", \"nm_empresa\" ] ).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados[ \"nr_voo\" ].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "O numero de voo mais comum é 2317 , seguido de 2316, seguido de 248, 15 e 247\n",
    "Os menos comuns tem apenas 1 e são : 2263 , 6565, 595, 6566 , 593\n",
    "Atente-se à amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.query( \"nr_voo == 2317\" )[ [ \"nm_empresa\", \"nr_voo\", \"nr_singular\", \"id_di\", \"nm_municipio_destino\", \"nm_municipio_origem\", \"dt_referencia\" ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados[ \"dt_referencia\" ] = pd.to_datetime( microdados.dt_referencia, infer_datetime_format = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.groupby( [ \"nr_ano_referencia\", \"nr_mes_referencia\" ] ).mean()[ [ \"nr_ask\",\n",
    "                                                                             \"nr_rpk\",\n",
    "                                                                             \"nr_atk\",\n",
    "                                                                             \"nr_rtk\",\n",
    "                                                                             \"kg_peso\" ] ].sort_index( ascending = True ).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Análise dos Atrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "urls = list( voos_url )[ :5 ]\n",
    "\n",
    "\n",
    "def download_voos( url ):\n",
    "    return pd.read_csv( url, skiprows = 1, sep = \";\" )\n",
    "\n",
    "\n",
    "voos = pd.DataFrame()\n",
    "for url in tqdm( urls ):\n",
    "    parcial = download_voos( url )\n",
    "\n",
    "    voos = pd.concat( (parcial, voos), axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for data in [ \"Chegada Prevista\", \"Chegada Real\", \"Partida Prevista\", \"Partida Real\" ]:\n",
    "    voos[ data ] = pd.to_datetime( voos[ data ], infer_datetime_format = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos[ \"ano\" ] = voos[ \"Partida Real\" ].dt.year\n",
    "voos[ \"mes\" ] = voos[ \"Partida Real\" ].dt.month\n",
    "voos[ \"semana_ano\" ] = voos[ \"Partida Real\" ].dt.week\n",
    "voos[ \"dia_semana\" ] = voos[ \"Partida Real\" ].dt.dayofweek\n",
    "voos[ \"atraso_chegada\" ] = (voos[ \"Chegada Real\" ] - voos[ \"Chegada Prevista\" ]).dt.seconds / 60\n",
    "voos[ \"atraso_saida\" ] = (voos[ \"Partida Real\" ] - voos[ \"Partida Prevista\" ]).dt.seconds / 60\n",
    "voos[ \"atraso_ajustado\" ] = voos[ \"atraso_chegada\" ] - voos[ \"atraso_saida\" ]\n",
    "voos[ \"atraso_chegada_abs\" ] = abs( voos[ \"atraso_chegada\" ] )\n",
    "voos[ \"atraso_saida_abs\" ] = abs( voos[ \"atraso_saida\" ] )\n",
    "voos[ \"atraso_ajustado_abs\" ] = abs( voos[ \"atraso_ajustado\" ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos[ \"atraso_chegada\" ].plot( kind = \"hist\", bins = 100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Os dados concentrados à direita com cerca de 1400 minutos de atraso, o que corresponde a um dia, provavelmente são devido à mudança de um dia para outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos[ \"duracao_real\" ] = (voos[ \"Chegada Real\" ] - voos[ \"Partida Real\" ]).dt.seconds / 60\n",
    "voos[ \"duracao_prevista\" ] = (voos[ \"Chegada Prevista\" ] - voos[ \"Partida Prevista\" ]).dt.seconds / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(voos.query( \"atraso_chegada > 0 & atraso_chegada < 240\" ).groupby( [ \"ano\", \"mes\" ] )\n",
    " .agg(\n",
    "    percentil_10 = (\"atraso_chegada\", lambda x: x.quantile( 0.10 )),\n",
    "    percentil_20 = (\"atraso_chegada\", lambda x: x.quantile( 0.20 )),\n",
    "    percentil_30 = (\"atraso_chegada\", lambda x: x.quantile( 0.30 )),\n",
    "    percentil_40 = (\"atraso_chegada\", lambda x: x.quantile( 0.40 )),\n",
    "    percentil_50 = (\"atraso_chegada\", lambda x: x.quantile( 0.50 )),\n",
    "    percentil_60 = (\"atraso_chegada\", lambda x: x.quantile( 0.60 )),\n",
    "    percentil_70 = (\"atraso_chegada\", lambda x: x.quantile( 0.70 )),\n",
    "    percentil_80 = (\"atraso_chegada\", lambda x: x.quantile( 0.80 )),\n",
    "    percentil_90 = (\"atraso_chegada\", lambda x: x.quantile( 0.90 )),\n",
    ")[ [ \"percentil_10\",\n",
    "     \"percentil_20\",\n",
    "     \"percentil_30\",\n",
    "     \"percentil_40\",\n",
    "     \"percentil_50\",\n",
    "     \"percentil_60\",\n",
    "     \"percentil_70\",\n",
    "     \"percentil_80\",\n",
    "     \"percentil_90\" ] ].sort_index( ascending = True ).plot( figsize = (20, 20) )\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Doideira : um salto gigantesco no tamanho dos atrasos_saida e chegada, mas ambos acompanham uns aos outros.\n",
    "Uma possivel explicação é a presença da olimpiada no mesmo ano /periodo em que vemos esse crescimento acentuado. No entanto, era de se esperar que passado esse evento, tudo se normalizasse, mas\n",
    "não é o que observamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos.query( \"atraso_chegada > 0\" ).groupby( [ \"ano\", \"mes\" ] )[ [ \"atraso_chegada\",\n",
    "                                                                  \"atraso_saida\" ] ].mean().sort_index( ascending = True ).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Analisando somente os voos que atrasam, Vemos que a duração desses atrasos permanece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Será que os atrasos seguem algum tipo de padrão sazonal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos.groupby( \"semana_ano\" ).mean()[ [ \"atraso_chegada\",\n",
    "                                       \"atraso_saida\" ] ].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Novamente os atrasos de aproximadamente 1400 minutos (~ 24 horas) aparecem. Optamos por tratar tais atrasos como uma mudança de dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos.query( \"atraso_chegada > 0 \" ).groupby( \"dia_semana\" ).median()[ [ \"atraso_chegada\",\n",
    "                                                                        \"atraso_saida\" ] ].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Parece haver um efeito sazonal do dia da semana no que diz respeito aos atrasos.\n",
    "Peak atrasos ~ (terca )\n",
    "Menor ~ ( quinta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ids_linhas = [ 'N', 'E', 'R' ]\n",
    "ids_dis = [ '0', '4', 'C' ]\n",
    "\n",
    "voos = voos.rename( {\n",
    "    'Código Tipo Linha'      : 'id_tipo_linha',\n",
    "    'Código Autorização (DI)': 'cd_di'\n",
    "}, axis = 1 )\n",
    "voos = voos.query( 'id_tipo_linha in @ids_linhas' )\n",
    "voos = voos.query( 'cd_di in @ids_dis' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Filtrando apenas pelos municípios de SP e RJ, vemos que existem algumas empresas que nem conhecemos, bem como aeroportos que não conhecemos.\n",
    "\n",
    "Um filtro que faremos daqui em diante vai ser filtrar apenas voos de passageiros.\n",
    "Isso signfica apenas os códigos ( N , I, E , R).\n",
    "\n",
    "Um segundo filtro diz respeito aos voos internacionais: Não consideramos eles.\n",
    "Isso inviabiliza os voos com código I.\n",
    "\n",
    "Portanto consideramos apenas os códigos ( N , E , R )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Outra dimensão a ser considerada é o Digito Identificador.\n",
    "Ele diz respeito ao tipo de voo realizado. Podem ser dos seguintes tipos:\n",
    "Regular, Improdutivo, Não regular.\n",
    "Nesta analise consideraremos apenas os voos regulares.\n",
    "Estes são sinalizados com cd_di pertencente à ( 0 , 4 , C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Outro ponto a ser considerado é a situação do voo.\n",
    "Consideraremos apenas os voos Realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Correlação de atrasos com outras features\n",
    "Algum aeroporto atrasa mais que os outros? Isso pode ser causado pelo clima do aeroporto ou pela movimentação daquele aeroporto\n",
    "Horario do dia. ( Período manhã / tarde / noite )\n",
    "Sera que algum voo atrasa mais?\n",
    "Alguma companhia aerea?\n",
    "\n",
    "Lotação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Após a análise dos dados, definimos as features e fizemos o merge com os dados de clima para obtenção do dataset final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos = pd.read_sql( '''\n",
    "with\n",
    "\tresumo_voos as (\n",
    "\tselect\n",
    "\t\tdate(dt_partida_prevista)  as dt_referencia\n",
    "\t  , dt_chegada_real\n",
    "\t  , dt_chegada_prevista\n",
    "\t  , sg_empresa_icao\n",
    "\t  , origem.nm_municipio  as municipio_origem\n",
    "\t  , destino.nm_municipio as municipio_destino\n",
    "\t  , timestampdiff( minute ,    dt_chegada_prevista , dt_chegada_real ) as atrasado\n",
    "\t\tfrom\n",
    "\t\t\tvoos_sp_sj               voos\n",
    "\t\t\tinner join nrm_empresa   empresa on empresa.id_empresa = voos.id_empresa\n",
    "\t\t\tinner join nrm_aeroporto origem on origem.id_aerodromo = voos.id_aerodromo_origem\n",
    "\t\t\tinner join nrm_aeroporto destino on destino.id_aerodromo = voos.id_aerodromo_destino\n",
    "\t\twhere\n",
    "\t\t\t\tdt_partida_prevista >= '2014-12-30 00:00:00'\n",
    "\t\torder by\n",
    "\t\t\tdt_partida_prevista\n",
    "\t)\n",
    "\n",
    "SELECT *\n",
    "\tFROM\n",
    "\t\tresumo_voos\n",
    "''', database.engine )\n",
    "clima = pd.read_sql( \"\"\"\n",
    "select\n",
    "\tnm_municipio\n",
    "  , dt_referencia + interval 1 day as dt_referencia\n",
    "  , precipitacao_mm\n",
    "  , pressao_mb\n",
    "  , umidade_relativa\n",
    "  , temperatura_k\n",
    "  , vento_ms\n",
    "\tfrom\n",
    "\t\tresumo_clima\n",
    "                    \"\"\", database.engine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for column in voos.columns:\n",
    "    if column.startswith( \"dt\" ):\n",
    "        voos[ column ] = pd.to_datetime( voos[ column ], infer_datetime_format = True )\n",
    "for column in clima.columns:\n",
    "    if column.startswith( \"dt\" ):\n",
    "        clima[ column ] = pd.to_datetime( clima[ column ], infer_datetime_format = True )\n",
    "voos = voos.query( \"atrasado > -60\" )\n",
    "voos[ \"atrasado\" ] = voos[ \"atrasado\" ] >= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = voos.merge( clima, how = \"inner\",\n",
    "                 left_on = [ \"municipio_origem\", \"dt_referencia\" ],\n",
    "                 right_on = [ \"nm_municipio\", \"dt_referencia\" ] )\n",
    "df[ \"dia_semana\" ] = df[ \"dt_referencia\" ].dt.dayofweek\n",
    "df[ \"semana_ano\" ] = df[ \"dt_referencia\" ].dt.weekofyear\n",
    "numericas = [ \"precipitacao_mm\", \"pressao_mb\", \"umidade_relativa\", \"temperatura_k\", \"vento_ms\" ]\n",
    "categoricas = [ \"sg_empresa_icao\",\n",
    "                \"municipio_origem\",\n",
    "                \"municipio_destino\",\n",
    "                \"dia_semana\",\n",
    "                \"semana_ano\" ]\n",
    "columns_keep = [ ]\n",
    "columns_keep.extend( numericas )\n",
    "columns_keep.extend( categoricas )\n",
    "columns_keep.append( \"atrasado\" )\n",
    "columns_keep.append( \"dt_referencia\" )\n",
    "df = df[ columns_keep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['atrasado'] = df['atrasado'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df[ numericas + ['atrasado'] ], alpha = 0.2, figsize = ( 12, 12 ), diagonal = 'kde' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A scatter matrix não mostra nenhuma correlação muito forte entre as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "corr = df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    vmin = -1,\n",
    "    vmax = 1,\n",
    "    center = 0,\n",
    "    cmap = sns.diverging_palette( 20, 220, n = 200 ),\n",
    "    square = True\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "O heatmap mostra que há pouca correlação grande maioria das variáveis, inclusive havendo correlações negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "É importante observar que os filtros definidos para simplificação do modelo remove grande parte dos dados existentes. Com mais tempo, seria interessante fazer uma análise mais detalhada e com os dados completos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Fazendo a limpeza dos dados NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2.isna().sum(axis=0)/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Como aproximadamente 5% dos dados relacionados ao clima são NA, optamos por dropa-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Modelo de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_y = df[ [ \"atrasado\" ] ]\n",
    "df_x = df[ columns_keep ].drop( [ \"atrasado\", \"dt_referencia\" ], axis = 1 )\n",
    "(df_train_x, df_test_x,\n",
    " df_train_y, df_test_y) = train_test_split( df_x, df_y,\n",
    "                                            train_size = 0.8,\n",
    "                                            stratify = df_y )\n",
    "encoder = TargetEncoder( cols = categoricas,\n",
    "                         handle_unknown = 'value' ).fit( df_train_x, df_train_y )\n",
    "df_train_x = encoder.transform( df_train_x )\n",
    "df_test_x = encoder.transform( df_test_x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Inicialmente optamos por treinar um modelo de Regressão Logística e um Floresta Aleatória como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest: RandomForestClassifier = RandomForestClassifier( max_depth = 4, random_state = 1, )\n",
    "forest: RandomForestClassifier = forest.fit( df_train_x, df_train_y )\n",
    "df_train_yhat_forest = forest.predict_proba( df_train_x )[ :, [ 1 ] ]\n",
    "df_test_yhat_forest = forest.predict_proba( df_test_x )[ :, [ 1 ] ]\n",
    "logistic: LogisticRegression = LogisticRegression()\n",
    "logistic = logistic.fit( df_train_x, df_train_y )\n",
    "df_train_yhat_logistic = logistic.predict_proba( df_train_x )[ :, [ 1 ] ]\n",
    "df_test_yhat_logistic = logistic.predict_proba( df_test_x )[ :, [ 1 ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Métricas do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for train, test in ((df_train_yhat_forest, df_test_yhat_forest),\n",
    "                    (df_train_yhat_logistic, df_test_yhat_logistic)):\n",
    "    threshold = np.percentile( train, 50 )\n",
    "    print( threshold )\n",
    "    y_true = df_test_y\n",
    "    y_pred = test >= threshold\n",
    "    normalize = None\n",
    "    cm = confusion_matrix( y_true,\n",
    "                           y_pred, normalize = normalize,\n",
    "                           )\n",
    "    predictions = ConfusionMatrixDisplay.from_predictions( y_true = y_true, y_pred = y_pred,\n",
    "                                                           normalize = normalize, cmap = 'Blues' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Métricas com cross_val_predict para o Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "df_train_pred_y = cross_val_predict( forest2, df_train_x, df_train_y, cv = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix( df_train_y, df_train_pred_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix( df_test_y, df_test_yhat_forest >= 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(confusion_matrix( df_train_y, df_train_pred_y , normalize='true'))\n",
    "pprint(confusion_matrix( df_test_y, df_test_yhat_forest >= 0.5 , normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "É possível ver que os dados de treino e teste apresentam resultados bastante semelhantes, o que é um bom sinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = ConfusionMatrixDisplay.from_predictions( y_true = df_train_y, y_pred = df_train_pred_y, normalize = normalize, cmap = 'Blues' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf_norm = confusion_matrix( df_train_y, df_train_pred_y , normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(f'Precision: {precision_score(df_train_y, df_train_pred_y)}')\n",
    "print(f'Recall (Sensitivity): {recall_score(df_train_y, df_train_pred_y)}')\n",
    "print(f'F1 Score: {f1_score(df_train_y, df_train_pred_y)}')\n",
    "print(f'Specificity: {conf_norm[0,0]/(conf_norm[0,0]+conf_norm[0,1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* O Recall mostra que aproximadamente 71% dos voos que atrasaram foram corretamente identificados pelo modelo.\n",
    "* A Specificity mostra que aproxidamente 82% dos voos que não atrasaram foram corretamente identificados pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report( df_train_y, df_train_pred_y ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot( [ 0, 1 ], [ 0, 1 ] )\n",
    "plot_roc_curve( forest, df_train_x, df_train_y, ax = ax )\n",
    "plot_roc_curve( logistic, df_train_x, df_train_y, ax = ax )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nestas condições, é possível observar que a performance do modelo Random Forest é superior à do Logistic Regression. O AUC é extremamente útil para esta comparação.\n",
    "Além disso talvez fosse interessante considerar a Precision ao invés de False Positive Rate caso os dados fossem muito desbalanceados, o que é uma estratégia interessante pelo fato de o Precision não levar em conta os true negatives. No nosso caso cerca de 25% dos voos atrasam, então talvez não tenha muita diferença."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ajuste fino do modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parâmetros usados atualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Parâmetros usados atualmente:\\n')\n",
    "pprint(forest.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Randomized Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [ int(x) for x in np.linspace( start = 200, stop = 2000, num = 10 ) ]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Treinando o modelo com Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest_random = RandomizedSearchCV( estimator = forest,\n",
    "                                    param_distributions = random_grid,\n",
    "                                    n_iter = 100,\n",
    "                                    cv = 5,\n",
    "                                    verbose = 2,\n",
    "                                    random_state = 1,\n",
    "                                    n_jobs = -1 )\n",
    "\n",
    "forest_random.fit( df_train_x, df_train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Comparação entre o modelo base e o modelo com os hyper parâmetros ajustados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def avalia_modelo(modelo, x_test, y_test):\n",
    "    y_pred = modelo.predict(x_test)\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "    print(f'Recall (Sensitivity): {recall_score(y_test, y_pred)}')\n",
    "    print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "    print(f\"Specificity: {confusion_matrix(y_test, y_pred, normalize='true')[0,0]/(confusion_matrix(y_test, y_pred, normalize='true')[0,0]+confusion_matrix(y_test, y_pred, normalize='true')[0,1])}\")\n",
    "    print(f'AUC: {roc_auc_score(y_test, y_pred)}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'ROC: {roc_curve(y_test, y_pred)}')\n",
    "    print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "    print(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "\n",
    "avalia_modelo(forest, df_test_x, df_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Modelo com ajuste de hyper parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avalia_modelo(forest_random.best_estimator_, df_test_x, df_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot( [ 0, 1 ], [ 0, 1 ] )\n",
    "plot_roc_curve( forest_random.best_estimator_, df_test_x, df_test_y, ax = ax, name='Random Forest Tunado' )\n",
    "plot_roc_curve( forest, df_test_x, df_test_y, ax = ax, name='Random Forest Base' )\n",
    "plot_roc_curve( logistic, df_test_x, df_test_y, ax = ax, name='Logistic Regression' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "É possível notar que o modelo com ajuste de hyper parâmetros tem uma performance melhor que o modelo base, com um acréscimo de quase 5% na maiora das métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest_random.best_estimator_.feature_importances_\n",
    "for feature, score in zip(df_train_x.columns, forest_random.best_estimator_.feature_importances_):\n",
    "    print(f'{feature}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Para finalizar, a semana do ano é a feature mais importante do modelo com ajuste de hyper parâmetros. O que faz todo o sentido uma vez que está diretamente relacionada à datas de feriados e férias e  consequentemente à movimentação nos aeroportos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}