{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtenção e primeira exploração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import database\n",
    "from voos import voos_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microdados = pd.DataFrame()\n",
    "\n",
    "urls = [ ]\n",
    "for year in range( 2020, 2020 + 1 ):\n",
    "\tfor month in range( 1, 12 + 1 ):\n",
    "\t\tmonth = str( month ) if month >= 10 else \"0\" + str( month )\n",
    "\t\turl = f\"https://www.gov.br/anac/pt-br/assuntos/regulados/empresas-aereas/envio-de-informacoes/microdados/basica{year}-{month}.zip\"\n",
    "\t\turls.append( url )\n",
    "\n",
    "for url in tqdm( urls ):\n",
    "\tparcial = pd.read_csv( url, encoding = \"latin1\", sep = \";\" ).sample( frac = 0.05, random_state = 2 )\n",
    "\tmicrodados = pd.concat( [ microdados, parcial ], axis = 0 )\n",
    "\n",
    "url_est = 'https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/dados-estatisticos/arquivos/resumo_anual_2010.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Da definição:\n",
    "\n",
    "# Etapa Básica (flight stage): As etapas básicas são aquelas realizadas pela aeronave desde a sua decolagem até o próximo pouso, independentemente de onde tenha ocorrido o embarque ou o desembarque do objeto de transporte.\n",
    "#\n",
    "# Os dados estatísticos das etapas básicas representam o status da aeronave em cada etapa do voo, apresentando a movimentação de cargas e passageiros entre os aeródromos de origem e destino da aeronave. É a operação de uma aeronave entre um a decolagem e o próximo pouso, a ligação entre dois aeródromos.\n",
    "\n",
    "# Etapa Combinada (On flight origin and destination - OFOD): As etapas combinadas identificam os pares de origem, onde ocorreu o embarque do objeto de transporte, e destino, onde ocorreu o desembarque do objeto de transporte, independentemente da existência de aeródromos intermediários, atendidos por determinado voo.\n",
    "\n",
    "# É a etapa de voo vista com foco no objeto de transporte (pessoas e/ou cargas), com base no embarque e no desembarque nos aeródromos relacionados. Os dados estatísticos da etapa combinada informam a origem e destino dos passageiros e cargas transportadas no voo, independentemente das escalas realizadas.\n",
    "\n",
    "\n",
    "#Aqui olharemos primeiramente para a etapa basica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.duplicated( [ \"id_basica\" ] ).sum()\n",
    "# de Fato, id basica é uma pk ( identificador unico ) nessa tabela, e não temos nenhum registro duplicado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(microdados.isna().sum( axis = 0 ) / microdados.shape[ 0 ]).sort_values( ascending = False )\n",
    "\n",
    "# nr escala destino é 100% nulo. Doideira ( Isso provavelmente é algum tipo de informação que foi dropada ao longo do tempo. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "unique = microdados.nm_empresa.value_counts()\n",
    "cumulative = unique.cumsum()\n",
    "cumulative = cumulative / unique.sum()\n",
    "cumulative.sort_values( ascending = True ).iloc[ :15 ].plot( kind = \"bar\" )\n",
    "\n",
    "# Nenhuma surpresa aqui: a gigantesca maioria das etapas é realizada por poucas empresas\n",
    "# Aprox. 80% das etapas é feita por apenas 3;\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.groupby( [ \"nr_mes_referencia\", \"nm_mes_referencia\" ] ).count()[ \"id_basica\" ].sort_index( ascending = True ).plot( kind = \"bar\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados[ \"nr_dia_semana_referencia\" ] = pd.to_datetime( microdados[ \"dt_referencia\" ], infer_datetime_format = True ).dt.dayofweek\n",
    "\n",
    "microdados.groupby( [ \"nr_dia_semana_referencia\", \"nm_dia_semana_referencia\" ] ).count()[ \"id_basica\" ].sort_index( ascending = True ).plot( kind = \"bar\" )\n",
    "\n",
    "# Aqui temos uma surpresa: Fim de semanas são dias com menos voos? Interessante. [quinta, sexta, segunda, quarta, terca ] são dias de ocupação bem proxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.query( \"nm_pais != 'BRASIL'\" ).groupby( \"nm_pais\" ).nunique()[ \"nm_empresa\" ].nlargest( 10 ).plot( kind = \"bar\" )\n",
    "# Essas são as nacionalidades das empresas não brasileiras dentro do dataset. USA domina, seguido de argentina, chile, venezuela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.groupby( [ \"nm_municipio_destino\", \"nm_municipio_origem\", \"nm_empresa\" ] ).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados[ \"nr_voo\" ].value_counts()\n",
    "# O numero de voo mais comum é 2317 , seguido de 2316, seguido de 248, 15 e 247\n",
    "# Os menos comuns tem apenas 1 e são : 2263 , 6565, 595, 6566 , 593\n",
    "# Atente-se à amostragem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.query( \"nr_voo == 2317\" )[ [ \"nm_empresa\", \"nr_voo\", \"nr_singular\", \"id_di\", \"nm_municipio_destino\", \"nm_municipio_origem\", \"dt_referencia\" ] ]\n",
    "# O que identifica uma rota ( ORIGEM - DESTINO )  de maneira unica?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados[ \"dt_referencia\" ] = pd.to_datetime( microdados.dt_referencia, infer_datetime_format = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "microdados.groupby( [ \"nr_ano_referencia\", \"nr_mes_referencia\" ] ).mean()[ [ \"nr_ask\",\n",
    "                                                                             \"nr_rpk\",\n",
    "                                                                             \"nr_atk\",\n",
    "                                                                             \"nr_rtk\",\n",
    "                                                                             \"kg_peso\" ] ].sort_index( ascending = True ).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Atrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "urls = list( voos_url )[ :5 ]\n",
    "\n",
    "\n",
    "def download_voos( url ):\n",
    "\treturn pd.read_csv( url, skiprows = 1, sep = \";\" )\n",
    "\n",
    "\n",
    "voos = pd.DataFrame()\n",
    "for url in tqdm( urls ):\n",
    "\tparcial = download_voos( url )\n",
    "\n",
    "\tvoos = pd.concat( (parcial, voos), axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [ \"Chegada Prevista\", \"Chegada Real\", \"Partida Prevista\", \"Partida Real\" ]:\n",
    "\tvoos[ data ] = pd.to_datetime( voos[ data ], infer_datetime_format = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos[ \"ano\" ] = voos[ \"Partida Real\" ].dt.year\n",
    "voos[ \"mes\" ] = voos[ \"Partida Real\" ].dt.month\n",
    "voos[ \"semana_ano\" ] = voos[ \"Partida Real\" ].dt.week\n",
    "voos[ \"dia_semana\" ] = voos[ \"Partida Real\" ].dt.dayofweek\n",
    "voos[ \"atraso_chegada\" ] = (voos[ \"Chegada Real\" ] - voos[ \"Chegada Prevista\" ]).dt.seconds / 60\n",
    "voos[ \"atraso_saida\" ] = (voos[ \"Partida Real\" ] - voos[ \"Partida Prevista\" ]).dt.seconds / 60\n",
    "voos[ \"atraso_ajustado\" ] = voos[ \"atraso_chegada\" ] - voos[ \"atraso_saida\" ]\n",
    "voos[ \"atraso_chegada_abs\" ] = abs( voos[ \"atraso_chegada\" ] )\n",
    "voos[ \"atraso_saida_abs\" ] = abs( voos[ \"atraso_saida\" ] )\n",
    "voos[ \"atraso_ajustado_abs\" ] = abs( voos[ \"atraso_ajustado\" ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos[ \"atraso_chegada\" ].plot( kind = \"hist\", bins = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos[ \"duracao_real\" ] = (voos[ \"Chegada Real\" ] - voos[ \"Partida Real\" ]).dt.seconds / 60\n",
    "voos[ \"duracao_prevista\" ] = (voos[ \"Chegada Prevista\" ] - voos[ \"Partida Prevista\" ]).dt.seconds / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(voos.query( \"atraso_chegada > 0 & atraso_chegada < 240\" ).groupby( [ \"ano\", \"mes\" ] )\n",
    " .agg(\n",
    "\tpercentil_10 = (\"atraso_chegada\", lambda x: x.quantile( 0.10 )),\n",
    "\tpercentil_20 = (\"atraso_chegada\", lambda x: x.quantile( 0.20 )),\n",
    "\tpercentil_30 = (\"atraso_chegada\", lambda x: x.quantile( 0.30 )),\n",
    "\tpercentil_40 = (\"atraso_chegada\", lambda x: x.quantile( 0.40 )),\n",
    "\tpercentil_50 = (\"atraso_chegada\", lambda x: x.quantile( 0.50 )),\n",
    "\tpercentil_60 = (\"atraso_chegada\", lambda x: x.quantile( 0.60 )),\n",
    "\tpercentil_70 = (\"atraso_chegada\", lambda x: x.quantile( 0.70 )),\n",
    "\tpercentil_80 = (\"atraso_chegada\", lambda x: x.quantile( 0.80 )),\n",
    "\tpercentil_90 = (\"atraso_chegada\", lambda x: x.quantile( 0.90 )),\n",
    ")[ [ \"percentil_10\",\n",
    "\t \"percentil_20\",\n",
    "\t \"percentil_30\",\n",
    "\t \"percentil_40\",\n",
    "\t \"percentil_50\",\n",
    "\t \"percentil_60\",\n",
    "\t \"percentil_70\",\n",
    "\t \"percentil_80\",\n",
    "\t \"percentil_90\" ] ].sort_index( ascending = True ).plot( figsize = (20, 20) )\n",
    " )\n",
    "# Doideira : um salto gigantesco no tamanho dos atrasos_saida e chegada, mas ambos acompanham uns aos outros.\n",
    "# #Uma possivel explicação é a presença da olimpiada no mesmo ano /periodo em que vemos esse crescimento acentuado. No entanto, era de se esperar que passado esse evento, tudo se normalizasse, mas\n",
    "# não é o que observamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos.query( \"atraso_chegada > 0\" ).groupby( [ \"ano\", \"mes\" ] )[ [ \"atraso_chegada\",\n",
    "                                                                  \"atraso_saida\" ] ].mean().sort_index( ascending = True ).plot()\n",
    "\n",
    "# Analisando somente os voos que atrasam, Vemos que a duração desses atrasos permanece razoavelmente constante. ao redor de 600 +- 100, Com excessão desse evento proximo a 2017-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sera que os atrasos seguem algum tipo de padrão sazonal?\n",
    "\n",
    "voos.groupby( \"semana_ano\" ).mean()[ [ \"atraso_chegada\",\n",
    "                                       \"atraso_saida\" ] ].plot()\n",
    "\n",
    "# Temos um descolamento entre  chegada e saida ao redor da semana 40.\n",
    "\n",
    "# Nao estou vendo muito padrão nao. Talvez necessitamos de mais variaveis, ou talvez seja com o dia do mes / dia da semana.\n",
    "# Talvez durante a transição de horario de verão?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos.query( \"atraso_chegada > 0 \" ).groupby( \"dia_semana\" ).median()[ [ \"atraso_chegada\",\n",
    "                                                                        \"atraso_saida\" ] ].plot()\n",
    "\n",
    "# Parece haver um efeito sazonal do dia da semana no que diz respeito aos atrasos.\n",
    "# Peak atrasos ~ (terca )\n",
    "# Menor ~ ( quinta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_linhas = [ 'N', 'E', 'R' ]\n",
    "ids_dis = [ '0', '4', 'C' ]\n",
    "\n",
    "voos = voos.rename( {\n",
    "\t\t'Código Tipo Linha'      : 'id_tipo_linha',\n",
    "\t\t'Código Autorização (DI)': 'cd_di'\n",
    "\t\t}, axis = 1 )\n",
    "voos = voos.query( 'id_tipo_linha in @ids_linhas' )\n",
    "voos = voos.query( 'cd_di in @ids_dis' )\n",
    "# Filtrando apenas pelos municípios de SP e RJ, vemos que existem algumas empresas que nem conhecemos, bem como aeroportos que não conhecemos.\n",
    "\n",
    "# Um filtro que faremos daqui em diante vai ser filtrar apenas voos de passageiros.\n",
    "# Isso signfica apenas os códigos ( N , I, E , R).\n",
    "\n",
    "# Um segundo filtro diz respeito aos voos internacionais: Não consideramos eles.\n",
    "# Isso inviabiliza os voos com código I.\n",
    "\n",
    "# Portanto consideramos apenas os códigos ( N , E , R )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outra dimensão a ser considerada é o Digito Identificador.\n",
    "# Ele diz respeito ao tipo de voo realizado. Podem ser dos seguintes tipos:\n",
    "# Regular, Improdutivo, Não regular.\n",
    "# Nesta analise consideraremos apenas os voos regulares.\n",
    "# Estes são sinalizados com cd_di pertencente à ( 0 , 4 , C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outro ponto a ser considerado é a situação do voo.\n",
    "# Consideraremos apenas os voos Realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação de atrasos com outras features\n",
    "# Algum aeroporto atrasa mais que os outros? Isso pode ser causado pelo clima do aeroporto ou pela movimentação daquele aeroporto\n",
    "# Horario do dia. ( Período manhã / tarde / noite )\n",
    "# Sera que algum voo atrasa mais?\n",
    "# Alguma companhia aerea?\n",
    "\n",
    "# Lotação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados para o modelo de Machine Learning\n",
    "## Limpeza\n",
    "## Tratamento\n",
    "## Feature engineering\n",
    "## Enriquecimento da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos = pd.read_sql( '''\n",
    "with\n",
    "\tresumo_voos as (\n",
    "\tselect\n",
    "\t\tdate(dt_partida_prevista)  as dt_referencia\n",
    "\t  , dt_chegada_real\n",
    "\t  , dt_chegada_prevista\n",
    "\t  , sg_empresa_icao\n",
    "\t  , origem.nm_municipio  as municipio_origem\n",
    "\t  , destino.nm_municipio as municipio_destino\n",
    "\t  , timestampdiff( minute ,    dt_chegada_prevista , dt_chegada_real ) as atrasado\n",
    "\t\tfrom\n",
    "\t\t\tvoos_sp_sj               voos\n",
    "\t\t\tinner join nrm_empresa   empresa on empresa.id_empresa = voos.id_empresa\n",
    "\t\t\tinner join nrm_aeroporto origem on origem.id_aerodromo = voos.id_aerodromo_origem\n",
    "\t\t\tinner join nrm_aeroporto destino on destino.id_aerodromo = voos.id_aerodromo_destino\n",
    "\t\twhere\n",
    "\t\t\t\tdt_partida_prevista >= '2014-12-30 00:00:00'\n",
    "\t\torder by\n",
    "\t\t\tdt_partida_prevista\n",
    "\t)\n",
    "\n",
    "SELECT *\n",
    "\tFROM\n",
    "\t\tresumo_voos\n",
    "''', database.engine )\n",
    "clima = pd.read_sql( \"\"\"\n",
    "select\n",
    "\tnm_municipio\n",
    "  , dt_referencia + interval 1 day as dt_referencia\n",
    "  , precipitacao_mm\n",
    "  , pressao_mb\n",
    "  , umidade_relativa\n",
    "  , temperatura_k\n",
    "  , vento_ms\n",
    "\tfrom\n",
    "\t\tresumo_clima\n",
    "                    \"\"\", database.engine )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voos = pd.read_sql( '''\n",
    "with\n",
    "\tresumo_voos as (\n",
    "\tselect\n",
    "\t\tdate(dt_partida_prevista)  as dt_referencia\n",
    "\t  , dt_chegada_real\n",
    "\t  , dt_chegada_prevista\n",
    "\t  , sg_empresa_icao\n",
    "\t  , origem.nm_municipio  as municipio_origem\n",
    "\t  , destino.nm_municipio as municipio_destino\n",
    "\t  , timestampdiff( minute ,    dt_chegada_prevista , dt_chegada_real ) as atrasado\n",
    "\t\tfrom\n",
    "\t\t\tvoos_sp_sj               voos\n",
    "\t\t\tinner join nrm_empresa   empresa on empresa.id_empresa = voos.id_empresa\n",
    "\t\t\tinner join nrm_aeroporto origem on origem.id_aerodromo = voos.id_aerodromo_origem\n",
    "\t\t\tinner join nrm_aeroporto destino on destino.id_aerodromo = voos.id_aerodromo_destino\n",
    "\t\twhere\n",
    "\t\t\t\tdt_partida_prevista >= '2014-12-30 00:00:00'\n",
    "\t\torder by\n",
    "\t\t\tdt_partida_prevista\n",
    "\t)\n",
    "\n",
    "SELECT *\n",
    "\tFROM\n",
    "\t\tresumo_voos\n",
    "''', database.engine )\n",
    "clima = pd.read_sql( \"\"\"\n",
    "select\n",
    "\tnm_municipio\n",
    "  , dt_referencia + interval 1 day as dt_referencia\n",
    "  , precipitacao_mm\n",
    "  , pressao_mb\n",
    "  , umidade_relativa\n",
    "  , temperatura_k\n",
    "  , vento_ms\n",
    "\tfrom\n",
    "\t\tresumo_clima\n",
    "                    \"\"\", database.engine )\n",
    "for column in voos.columns:\n",
    "\tif column.startswith( \"dt\" ):\n",
    "\t\tvoos[ column ] = pd.to_datetime( voos[ column ], infer_datetime_format = True )\n",
    "for column in clima.columns:\n",
    "\tif column.startswith( \"dt\" ):\n",
    "\t\tclima[ column ] = pd.to_datetime( clima[ column ], infer_datetime_format = True )\n",
    "voos = voos.query( \"atrasado > -60\" )\n",
    "voos[ \"atrasado\" ] = voos[ \"atrasado\" ] >= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = voos.merge( clima, how = \"left\",\n",
    "\t\tleft_on = [ \"municipio_origem\", \"dt_referencia\" ],\n",
    "\t\tright_on = [ \"nm_municipio\", \"dt_referencia\" ] )\n",
    "df[ \"dia_semana\" ] = df[ \"dt_referencia\" ].dt.dayofweek\n",
    "df[ \"semana_ano\" ] = df[ \"dt_referencia\" ].dt.weekofyear\n",
    "numericas = [ \"precipitacao_mm\", \"pressao_mb\", \"umidade_relativa\", \"temperatura_k\", \"vento_ms\" ]\n",
    "categoricas = [ \"sg_empresa_icao\",\n",
    "                \"municipio_origem\",\n",
    "                \"municipio_destino\",\n",
    "                \"dia_semana\",\n",
    "                \"semana_ano\" ]\n",
    "columns_keep = [ ]\n",
    "columns_keep.extend( numericas )\n",
    "columns_keep.extend( categoricas )\n",
    "columns_keep.append( \"atrasado\" )\n",
    "columns_keep.append( \"dt_referencia\" )\n",
    "df = df[ columns_keep ]\n",
    "df = (df\n",
    "      .sort_values( \"dt_referencia\" )\n",
    "      .groupby( \"municipio_origem\", as_index = False )\n",
    "      .fillna( method = \"ffill\" )\n",
    "      .dropna())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = (df\n",
    "\t  .sort_values( \"dt_referencia\" )\n",
    "\t  .groupby( \"municipio_origem\", as_index = False )\n",
    "\t  .fillna( method = \"ffill\" )\n",
    "\t  .dropna())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df[ [ \"atrasado\" ] ]\n",
    "df_x = df[ columns_keep ].drop( [ \"atrasado\", \"dt_referencia\" ], axis = 1 )\n",
    "(df_train_x, df_test_x,\n",
    " df_train_y, df_test_y) = train_test_split( df_x, df_y,\n",
    "\t\ttrain_size = 0.8,\n",
    "\t\tstratify = df_y )\n",
    "encoder = TargetEncoder( cols = categoricas,\n",
    "\t\thandle_unknown = 'value' ).fit( df_train_x, df_train_y )\n",
    "df_train_x = encoder.transform( df_train_x )\n",
    "df_test_x = encoder.transform( df_test_x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest: RandomForestClassifier = RandomForestClassifier( max_depth = 4, random_state = 1, )\n",
    "forest: RandomForestClassifier = forest.fit( df_train_x, df_train_y )\n",
    "df_train_yhat_forest = forest.predict_proba( df_train_x )[ :, [ 1 ] ]\n",
    "df_test_yhat_forest = forest.predict_proba( df_test_x )[ :, [ 1 ] ]\n",
    "logistic: LogisticRegression = LogisticRegression()\n",
    "logistic = logistic.fit( df_train_x, df_train_y )\n",
    "df_train_yhat_logistic = logistic.predict_proba( df_train_x )[ :, [ 1 ] ]\n",
    "df_test_yhat_logistic = logistic.predict_proba( df_test_x )[ :, [ 1 ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for train, test in ((df_train_yhat_forest, df_test_yhat_forest),\n",
    "                    (df_train_yhat_logistic, df_test_yhat_logistic)):\n",
    "\tthreshold = np.percentile( train, 80 )\n",
    "\tprint( threshold )\n",
    "\ty_true = df_test_y\n",
    "\ty_pred = test >= threshold\n",
    "\tnormalize = None\n",
    "\tcm = confusion_matrix( y_true,\n",
    "\t\t\ty_pred, normalize = normalize,\n",
    "\t\t\t)\n",
    "\tpredictions = ConfusionMatrixDisplay.from_predictions( y_true = y_true, y_pred = y_pred,\n",
    "\t\t\tnormalize = normalize, cmap = 'Blues' )\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot( [ 0, 1 ], [ 0, 1 ] )\n",
    "plot_roc_curve( forest, df_train_x, df_train_y, ax = ax )\n",
    "plot_roc_curve( logistic, df_train_x, df_train_y, ax = ax )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71fb1e84f78ab8ebcfca3373495fb3de3ecd3b92eeb87cad3f40b6fe4ea43cb0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
